
\documentclass[25pt, portrait,  margin=0mm, innermargin=15mm,
  blockverticalspace=15mm, colspace=15mm, subcolspace=8mm]{tikzposter}



\usepackage[utf8]{inputenc}
\usepackage{mathtools}
\usepackage{biblatex}

\usetheme{Basic}

\bibliography{sigproc}


\makeatletter
\setlength{\TP@visibletextwidth}{225cm}
\setlength{ \TP@visibletextheight}{120cm}
\makeatother

\title{FemtoGraph: A Pregel Based Shared-memory
  Graph Processing Library}

\author{
  \textbf{Alex Ballmer}\\
  \textit{Illinois Institute of Technology}\\
  alexandersballmer@gmail.com\\
  \textbf{Ioan Raicu}\\
  \textit{Illinois Institute of Technology}\\
  iraicu@cs.iit.edu\\
}

\nocite{Gz:1}\nocite{Gz:2}
\nocite{Gz:3}
\nocite{Gz:4}
\nocite{Gz:5}
\nocite{Gz:6}
\nocite{Gz:7}
\nocite{snapnets}


\geometry{paperwidth=243.84cm,paperheight=121.92cm}


\begin{document}

\maketitle

\begin{columns}
    \column{0.25}
    \block[roundedcorners=40]{Abstract} {


  The emerging applications for large graphs in big data science and social networks has led to the development of numerous parallel or distributed graph processing applications. The need for faster manipulation of graphs has driven the need to scale accross large core counts and many parallel machines. While distributed memory parallel systems continue to be used for high performance computing, some smaller systems make use of shared memory (SMP) and larger core counts. I hope to explore ways to utilize these larger shared memory systems by implementing a framework for manipulating graphs at a large scale. This system should be able to leverage and scale to very large core counts and provide a framework for later incorporating distributed processing across multiple nodes.
}


    \block[roundedcorners=40]{Related Work} {
      \textbf{Other Graph Processing Systems}\par
      The field of graph processing is very well defined with many existing commercial and opensource applications and tools available.
      \begin{itemize}
      \item \textbf{GraphLab} Single node or parallel asynchronous vertex-centric framework 
      \item \textbf{Hadoop} MapReduce based parallel framework using hdfs filesystem. While not designed for graph processing alone, a graph processing algorithm can be thought of as a series of chained MapReduce functions
      \item \textbf{Apache Spark} MapReduce based parallel framework faster than Hadoop with in-memory processing 
      \item \textbf{Apache Giraph} Application on top of Hadoop for dedicated graph processing
      \end{itemize}

      \textbf{Comparing Application Performance}\par
      We chose to use GraphLab as a reference point to judge application performance as it is designed to run in a shared memory configuration on a single node. 
      }

    \block[roundedcorners=40]{Vertex-Centric Algorithms} {
      FemtoGraph is based off of the Pregel Model of graph processing\\
      \textbf{Vertex-centric algorithms:} \textit{think like a vertex}
      \begin{itemize}
      \item Vertex-centric algorithms run within the context of a single vertex or groups of vertices
      \item Computation occurs in steps
      \item \textit{Synchronous} algorithms mandate each vertex must finish computation before executing the next step
      \item \textit{Asynchronous} algorithms allow vertices to finish computation before the next step
      \end{itemize}

      \textbf{Pregel Model}
      \begin{itemize}
      \item Computation occurs in synchronous \textit{supersteps}
      \item \textit{Compute function} called in parallel in the context of each vertex
      \item All compute functions must be called before next superstep
      \item Vertices can update edges and neighboring vertices
      \item Vertices can send messages to vertices in the \textit{next} superstep only
      \item Vertices can \textit{vote to halt}. Vertices un-halt upon receiving a message
      \item When all vertices are halted, the simulation ends
      \end{itemize}
      
      }

    \block[roundedcorners=40]{Implementation} {

      \begin{itemize}
      \item Written in C++ with Boost libraries
      \item Graph stored in adjacency list
      \item Message queue based on multiple Boost lockfree queues
      \item Uses normal std::thread for multithreading.
      \item Compute function is a user defined function run in the context of each vertex
      \item Compute functions are called in parallel
      \end{itemize}


    }
    \column{0.25}
    \block[roundedcorners=40]{Initial Problems} {
      \textbf{Initial FemtoGraph could not scale past 4 cores}
      \begin{itemize}
      \item  Very bad scaling
      \item Tried various graph storage techniques and threading patterns
      \item Little improvement
      \end{itemize}
      \begin{itemize}
      \item Initial message queue used global mutexes (not lockfree) 
      \item Profiling using callgrind showed bottleneck in message queue
      \end{itemize}
      \setcounter{figurecounter}{98}
      \begin{tikzfigure}[Callgrind profiling]
        \includegraphics[width=0.85\linewidth]{callgrind.png}
      \end{tikzfigure}
      \begin{itemize}
      \item Highlighted area shows message queue blocking until mutex is freed
      \end{itemize}
      

      }
    
    \block[roundedcorners=40]{Final Results} {
      \setcounter{figurecounter}{98}
      \begin{tikzfigure}[Scaling vs GraphLab\label{test_lable}]
        \includegraphics[width=0.95\linewidth]{vs.png}
        \end{tikzfigure}


    }
    \column{0.25}


    \block[roundedcorners=40]{Solution} {
      \begin{itemize}
      \item Message queue has been confirmed to be the bottleneck
      \item Global mutex is not fast enough for > 8 threads.
      \item Local mutexes for areas of message queue too complex to implement
      \item Eventually settled on Boost lockfree queue
      \item Performance improved immediately
      \item Can scale to 48 cores
      \end{itemize}
      \begin{tikzfigure}[Before lockfree queue\label{test_lable}]
        \includegraphics[width=0.95\linewidth]{before.png}
      \end{tikzfigure}
            \begin{tikzfigure}[After lockfree queue\label{test_lable}]
        \includegraphics[width=0.95\linewidth]{after.png}
      \end{tikzfigure}


    }

    \column{0.25}

    \block[roundedcorners=40]{GraphLab Comparison} {    
      \begin{itemize}
      \item Graphlab is efficient at low core counts
      \item GraphLab does not scale very well, though, only dropping a few seconds in trials up to 48 cores.
      \end{itemize}
      \begin{tikzfigure}[Graphlab Scaling Performance\label{test_lable}]
        \includegraphics[width=0.95\linewidth]{graphlab.png}
      \end{tikzfigure}      
    }

    \block[roundedcorners=40]{Pagerank} {
      Testing was done with the pagerank algorithm as a reference algorithm.
      \begin{itemize}
      \item  Pagerank is used in many real-wold machine learning and data analysis situations and algorithms.
      \item Pagerank ranks vertices in a graph in order of relative connectedness
      \item Defined by $\forall t \in P : r^{(t)}(t)  = (1-\alpha) \cdot r(t) + \alpha \sum_{(s,t) \in L} \frac{r^{(t-1)}(s)}{|L(s)|}$
      \end{itemize}
    }


    \block[roundedcorners=40]{Testing Conditions} {
      All trials were done with
      \begin{itemize}
      \item The pagerank algorithm with epsilon 0.5 and damping factor 0.5
      \item The Wikipedia Talk Network dataset from Stanford SNAP collection
      \item A 2 socket 48 core AMD server with NUMA
        
      \end{itemize}
    }
    \block[roundedcorners=40]{Citations} {
  % sigproc.bib is the name of the Bibliography in t
      \printbibliography
    }

    
\end{columns}
\end{document}
